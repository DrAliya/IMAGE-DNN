{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf04859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.optim import lr_scheduler\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils import data as D\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import lib\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48967f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 170498071/170498071 [00:28<00:00, 5905014.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Percentage of data to be used is  5\n",
      "17 49959 2500\n",
      "Files already downloaded and verified\n",
      "{'train': 2500, 'val': 10000}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "validation_ratio = 0.1\n",
    "random_seed = 10\n",
    "initial_lr = 0.1\n",
    "num_epoch = 300\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(112),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "transform_train=transform\n",
    "transform_validation=transform\n",
    "transform_test=transform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "# note that we are reducing the data hwew\n",
    "\n",
    "percentage=5\n",
    "print(\"Percentage of data to be used is \",percentage)\n",
    "num_train=percentage*len(train_dataset)//100\n",
    "indices=random.sample(list(np.arange(len(train_dataset))),num_train)\n",
    "# indices = torch.arange(num_train)\n",
    "print(min(indices),max(indices),len(indices))\n",
    "tr_1k = data_utils.Subset(train_dataset, indices)\n",
    "train_dataset=tr_1k\n",
    "\n",
    "\n",
    "train_loader = data_utils.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "                                     \n",
    "                                                                \n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "\n",
    "                   \n",
    "                                     \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "\n",
    "                                                     \n",
    "dataset_sizes={}\n",
    "dataset_sizes[\"train\"]=len(train_dataset)\n",
    "dataset_sizes[\"val\"]=len(testset)\n",
    "\n",
    "\n",
    "dataloaders={}\n",
    "dataloaders[\"train\"]=train_loader\n",
    "dataloaders[\"val\"]=test_loader\n",
    "\n",
    "print(dataset_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9b89d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zaarr/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/zaarr/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /Users/zaarr/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
      "100%|████████████████████████████████████████| 233M/233M [00:30<00:00, 7.94MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.alexnet(pretrained=True)\n",
    "# Here the size of each output sample is set to 2.\n",
    "model_ft.classifier[6] = nn.Linear(4096,10)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b780f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc before training tensor(0.0946, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "acc=lib.evaluate_model(model_ft,test_loader,dataset_sizes[\"val\"],device)\n",
    "print(\"Acc before training\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed4029a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "Training Loss: 0.2916 Acc: 0.9048\n",
      "val Loss: 0.8758 Acc: 0.7299\n",
      "tensor(0.7299, dtype=torch.float64) is better than 0.0\n",
      "Saving\n",
      "Time for an epoch train and val =  0.8137106498082479 minutes\n",
      "Epoch 1/1\n",
      "----------\n",
      "Training Loss: 0.1963 Acc: 0.9324\n",
      "val Loss: 0.8128 Acc: 0.7542\n",
      "tensor(0.7542, dtype=torch.float64) is better than tensor(0.7299, dtype=torch.float64)\n",
      "Saving\n",
      "Time for an epoch train and val =  0.795107368628184 minutes\n",
      "Training 2 complete in 1m 37s\n",
      "Best val Acc: 0.754200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "num_epochs=5\n",
    "model_state_path=\"simple_alexnet_cifar10\"+str(num_epochs)+\".pt\"\n",
    "model_ft=lib.simple_train(model_ft, criterion, optimizer_ft, exp_lr_scheduler, \n",
    "                dataloaders, dataset_sizes, device,num_epochs=num_epochs, model_state_path=model_state_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "129e2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc after training tensor(0.7542, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "acc=lib.evaluate_model(model_ft,test_loader,dataset_sizes[\"val\"],device)\n",
    "print(\"Acc after training\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657774fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
